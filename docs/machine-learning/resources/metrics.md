---
title: ML.NET のメトリック
description: ML.NET モデルのパフォーマンスを評価するために使用されるメトリックを理解する
ms.date: 12/17/2019
ms.openlocfilehash: 046e0a3feea2da702dfef5ca9ce4f498fce5fb26
ms.sourcegitcommit: 636af37170ae75a11c4f7d1ecd770820e7dfe7bd
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/07/2020
ms.locfileid: "91804823"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="5f3f5-103">メトリックを使って ML.NET モデルを評価する</span><span class="sxs-lookup"><span data-stu-id="5f3f5-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="5f3f5-104">ML.NET モデルの評価に使用されるメトリックを理解します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="5f3f5-105">評価メトリックは、モデルによって実行される機械学習タスクの種類に固有です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="5f3f5-106">たとえば、分類タスクの場合、モデルは、予測されたカテゴリと実際のカテゴリがどの程度一致しているかを測定することで評価されます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="5f3f5-107">また、クラスタリングでの評価は、クラスター化された項目それぞれが相互にどのくらい近いか、またクラスターとクラスターの間がどれくらい離れているかに基づいています。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="5f3f5-108">二項分類の評価メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="5f3f5-109">メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-109">Metrics</span></span>   |      <span data-ttu-id="5f3f5-110">説明</span><span class="sxs-lookup"><span data-stu-id="5f3f5-110">Description</span></span>      |  <span data-ttu-id="5f3f5-111">調査項目</span><span class="sxs-lookup"><span data-stu-id="5f3f5-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="5f3f5-112">**精度**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-112">**Accuracy**</span></span> |  <span data-ttu-id="5f3f5-113">[正確度](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification)は、テスト データ セットでの正しい予測の割合です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="5f3f5-114">これは、入力サンプルの総数に対する正しい予測数の比率です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="5f3f5-115">各クラスに属するサンプルの数が同様の場合に適しています。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="5f3f5-116">**1.00 に近いほど優れています**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="5f3f5-117">ただし、ぴったりの 1.00 は問題を示しています (通常: ラベル/ターゲットの漏えい、過剰適合、またはトレーニング データによるテスト)。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="5f3f5-118">テスト データのバランスが取れていない場合 (ほとんどのインスタンスがいずれかのクラスに属している場合)、データセットが小さいか、スコアが 0.00 または 1.00 に近く、正確度では実際に分類子の有効性がキャプチャされないので、追加のメトリックを確認する必要があります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn't really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="5f3f5-119">**AUC**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-119">**AUC**</span></span> |    <span data-ttu-id="5f3f5-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) または "*曲線下面積*" は、真陽性率と偽陽性率のスイープによって作成される曲線下面積を測定します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="5f3f5-121">**1.00 に近いほど優れています**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="5f3f5-122">モデルが許容されるには、0.50 より大きい必要があります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="5f3f5-123">AUC が 0.50 以下のモデルは役に立ちません。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="5f3f5-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-124">**AUCPR**</span></span> | <span data-ttu-id="5f3f5-125">aucPR または "*精度 - 再現率曲線の曲線下面積*":クラスが不均衡な (非常に偏ったデータセット) 場合の予測の成功の役に立つ測定。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-125">aucPR or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="5f3f5-126">**1.00 に近いほど優れています**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="5f3f5-127">1.00 に近い高スコアは、分類子が正確な結果を返していること (高精度) と、すべての肯定的な結果の大部分も返していること (高い再現率) を示します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="5f3f5-128">**F1 スコア**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-128">**F1-score**</span></span> | <span data-ttu-id="5f3f5-129">[F1 スコア](https://en.wikipedia.org/wiki/F1_score)は "*バランスの取れた F スコアまたは F メジャー*" とも呼ばれます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="5f3f5-130">これは精度と再現率の調和平均です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="5f3f5-131">F1 スコアは、精度と再現率のバランスを取る場合に役立ちます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="5f3f5-132">**1.00 に近いほど優れています**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="5f3f5-133">F1 スコアは 1.00 で最高値に到達し、0.00 で最低スコアに到達します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="5f3f5-134">分類子の精度がわかります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="5f3f5-135">二項分類メトリックの詳細については、以下の記事を参照してください。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="5f3f5-136">正確度、精度、再現率、または F1?</span><span class="sxs-lookup"><span data-stu-id="5f3f5-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="5f3f5-137">BinaryClassificationMetrics クラス</span><span class="sxs-lookup"><span data-stu-id="5f3f5-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="5f3f5-138">精度 - 再現率曲線と ROC 曲線の関係</span><span class="sxs-lookup"><span data-stu-id="5f3f5-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="5f3f5-139">多クラス分類の評価メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="5f3f5-140">メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-140">Metrics</span></span>   |      <span data-ttu-id="5f3f5-141">説明</span><span class="sxs-lookup"><span data-stu-id="5f3f5-141">Description</span></span>      |  <span data-ttu-id="5f3f5-142">調査項目</span><span class="sxs-lookup"><span data-stu-id="5f3f5-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="5f3f5-143">**マイクロ正確度**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="5f3f5-144">[マイクロ平均正確度](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy)では、すべてのクラスのコントリビューションを集計して平均メトリックが計算されます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="5f3f5-145">正しく予測されたインスタンスの割合です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="5f3f5-146">マイクロ平均には、クラスのメンバーシップが考慮されません。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="5f3f5-147">基本的に、すべてのサンプルとクラスのペアが、精度メトリックに均等に作用します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="5f3f5-148">**1.00 に近いほど優れています**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="5f3f5-149">多クラス分類タスクで、マイクロ正確度の方がマクロ正確度よりも適しているのは、クラスの不均衡があると思われる場合です (言い換えると、</span><span class="sxs-lookup"><span data-stu-id="5f3f5-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="5f3f5-150">あるクラスが他のクラスよりも例の数が多い場合です)。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="5f3f5-151">**マクロ正確度**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="5f3f5-152">[マクロ平均正確度](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy)はクラス レベルの平均正確度です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="5f3f5-153">各クラスの正確度が計算され、マクロ正確度はこれらの正確度の平均です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="5f3f5-154">基本的に、すべてのクラスが、精度メトリックに均等に作用します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="5f3f5-155">少数派のクラスは、大規模なクラスと同じ重みが与えられています。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="5f3f5-156">マクロ平均メトリックでは、データセットにそのクラスのインスタンスがいくつ含まれていても、各クラスに同じ重みが与えられます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="5f3f5-157">**1.00 に近いほど優れています**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="5f3f5-158">クラスごとに独立してメトリックを計算してから、平均を受け取ります (そのため、すべてのクラスを平等に扱います)。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="5f3f5-159">**対数損失**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-159">**Log-loss**</span></span>| <span data-ttu-id="5f3f5-160">対数損失では、予測入力が 0.00 と 1.00 の間の確率値である分類モデルのパフォーマンスを測定します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-160">Logarithmic loss measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="5f3f5-161">予測される確率が実際のラベルから分岐すると、対数損失が増加します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="5f3f5-162">**0.00 に近いほど、優れています**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="5f3f5-163">完璧なモデルの対数損失は 0.00 になります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="5f3f5-164">機械学習モデルの目的はこの値を最小にすることです。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="5f3f5-165">**対数損失の減少**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="5f3f5-166">[対数損失の減少](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction)は、ランダム予測よりも優れている分類子の利点と解釈できます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="5f3f5-167">**範囲は -inf から 1.00 です。ここで、1.00 は完璧な予測であり、0.00 は平均の予測を示します**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="5f3f5-168">たとえば、値が 0.20 の場合、"正しい予測の確率は、ランダムな推測よりも 20% 優れている" と解釈できます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="5f3f5-169">マイクロ正確度は、一般に、ML 予測のビジネス ニーズにより適しています。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="5f3f5-170">多クラス分類タスクの品質を選択するために 1 つのメトリックを選択する場合は、通常、それはマイクロ正確度です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="5f3f5-171">サポート チケット分類タスクの例: (受け取るチケットをサポート チームに割り当てる)</span><span class="sxs-lookup"><span data-stu-id="5f3f5-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="5f3f5-172">マイクロ正確度 -- 受け取るチケットが適切なチームに分類される頻度はどのくらいですか。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="5f3f5-173">マクロ正確度 -- 平均的なチームの場合、受け取るチケットがそのチームにとって正しい頻度はどのくらいですか。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="5f3f5-174">この例で、マクロ正確度は、小規模なチームには重すぎます。年間 10 枚のチケットのみを取得する小規模なチームが、チケットが年間 10,000 枚の大規模なチームと重要度が同じになります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="5f3f5-175">このケースのマイクロ正確度は、"チケット ルーティング プロセスを自動化することで、会社がどれくらいの時間/お金を節約できるか" というビジネス ニーズとより相関しています。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="5f3f5-176">多クラス分類メトリックの詳細については、以下の記事を参照してください。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="5f3f5-177">精度、再現率、および F スコアのマイクロ平均とマクロ平均</span><span class="sxs-lookup"><span data-stu-id="5f3f5-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="5f3f5-178">不均衡なデータセットによる多クラス分類</span><span class="sxs-lookup"><span data-stu-id="5f3f5-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="5f3f5-179">回帰とレコメンデーションの評価メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="5f3f5-180">回帰タスクとレコメンデーション タスクの両方によって数値が予測されます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="5f3f5-181">回帰の場合、この数値には、入力プロパティの影響を受ける任意の出力プロパティを指定できます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="5f3f5-182">レコメンデーションの場合、この数値は、通常、評価値 (たとえば 1 から 5) か、はい/いいえのレコメンデーション (1 と0 で表現) です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="5f3f5-183">メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-183">Metric</span></span>   |      <span data-ttu-id="5f3f5-184">Description</span><span class="sxs-lookup"><span data-stu-id="5f3f5-184">Description</span></span>      |  <span data-ttu-id="5f3f5-185">調査項目</span><span class="sxs-lookup"><span data-stu-id="5f3f5-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="5f3f5-186">**R-2 乗**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-186">**R-Squared**</span></span> |  <span data-ttu-id="5f3f5-187">[R-2 乗 (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination)、または "*決定係数*" では、モデルの予測係数が -inf から 1.00 の間の値として表されます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="5f3f5-188">1.00 は完全な適合があることを意味します。適合は任意に低くなる可能性があるのでスコアはマイナスになることがあります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="5f3f5-189">0.00 のスコアは、モデルがラベルの期待値を推測していることを意味します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="5f3f5-190">R2 では、実際のテスト データ値が予測値にどのくらい近いかを測定します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="5f3f5-191">**1.00 に近いほど、高品質です**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="5f3f5-192">ただし、低い R-2 乗値 (0.50 など) がシナリオにとって完全に正常または十分である場合があり、高い R-2 乗値が常に優れているとは限らず、疑わしい場合もあります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="5f3f5-193">**絶対損失**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-193">**Absolute-loss**</span></span> |  <span data-ttu-id="5f3f5-194">[絶対損失](https://en.wikipedia.org/wiki/Mean_absolute_error)または "*平均絶対誤差 (MAE)*" では、予測が実際の結果にどのくらい近いかを測定します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="5f3f5-195">これはすべてのモデルの誤差の平均です。モデルの誤差とは、予測されたラベル値と正確なラベル値の間の絶対的な距離です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="5f3f5-196">この予測の誤差は、テスト データ セットの各レコードに対して計算されます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="5f3f5-197">最後に、記録されたすべての絶対誤差について平均値が計算されます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="5f3f5-198">**0.00 に近いほど、高品質です。**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="5f3f5-199">平均絶対誤差には、測定されるデータと同じスケールが使用されます (特定の範囲に正規化されません)。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="5f3f5-200">絶対損失、2 乗損失、および RMS 損失は、同じデータセット、またはラベル値の分布が同様のデータセットのモデル間の比較にのみ使用できます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="5f3f5-201">**2 乗損失**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-201">**Squared-loss**</span></span> |  <span data-ttu-id="5f3f5-202">[2 乗損失](https://en.wikipedia.org/wiki/Mean_squared_error)または "*平均 2 乗誤差 (MSE)*" ("*平均 2 乗偏差 (MSD)*" とも呼ばれます) で、回帰直線が一連のテスト データ値にどのくらい近いかがわかります。これを行うには、点から回帰直線までの距離 (これらの距離が誤差 E です) を受け取り、2 乗します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="5f3f5-203">2 乗すると、差が大きいほど、重みが大きくなります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="5f3f5-204">これは常に負以外であり、**値が 0.00 に近いほど優れています**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="5f3f5-205">データによっては、平均 2 乗誤差の値を非常に小さくすることができない場合があります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="5f3f5-206">**RMS 損失**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-206">**RMS-loss**</span></span> |  <span data-ttu-id="5f3f5-207">[RMS 損失](https://en.wikipedia.org/wiki/Root-mean-square_deviation)または "*平均 2 乗誤差平方根 (RMSE)*" ("*平均 2 乗偏差平方根 (RMSD)*" とも呼ばれます) では、モデルによって予測された値と、モデル化されている環境から観察された値の差を測定します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="5f3f5-208">RMS 損失は 2 乗損失の平方根であり、ラベルと単位が同じです。絶対損失と似ていますが、差が大きいほど、重みが大きくなります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="5f3f5-209">平均 2 乗誤差平方根は、一般的に、気候学、予測、および回帰分析で実験結果を検証するために使用されます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="5f3f5-210">これは常に負以外であり、**値が 0.00 に近いほど優れています**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="5f3f5-211">RMSD は、スケールに依存するため、データセット間ではなく、特定のデータセットに対する異なるモデルの予測誤差を比較するための正確度の測定です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="5f3f5-212">回帰メトリックの詳細については、以下の記事を参照してください。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="5f3f5-213">回帰分析:R-2 乗を解釈して適合度を評価する方法</span><span class="sxs-lookup"><span data-stu-id="5f3f5-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="5f3f5-214">回帰分析で R-2 乗を解釈する方法</span><span class="sxs-lookup"><span data-stu-id="5f3f5-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="5f3f5-215">R-2 乗の定義</span><span class="sxs-lookup"><span data-stu-id="5f3f5-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="5f3f5-216">平均 2 乗誤差の定義</span><span class="sxs-lookup"><span data-stu-id="5f3f5-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="5f3f5-217">平均 2 乗誤差と平均 2 乗誤差平方根とは</span><span class="sxs-lookup"><span data-stu-id="5f3f5-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="5f3f5-218">クラスタリングの評価メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="5f3f5-219">メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-219">Metric</span></span>   |      <span data-ttu-id="5f3f5-220">Description</span><span class="sxs-lookup"><span data-stu-id="5f3f5-220">Description</span></span>      |  <span data-ttu-id="5f3f5-221">調査項目</span><span class="sxs-lookup"><span data-stu-id="5f3f5-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="5f3f5-222">**平均距離**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-222">**Average Distance**</span></span>|<span data-ttu-id="5f3f5-223">データ ポイントと割り当てられたクラスターの中心との距離の平均です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="5f3f5-224">平均距離は、データ ポイントからクラスターの重心までの近接度を表す測定値です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="5f3f5-225">これはクラスターがどのくらい "密" であるかを測定します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="5f3f5-226">**0** に近い値ほど適当。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-226">Values closer to **0** are better.</span></span> <span data-ttu-id="5f3f5-227">平均距離がゼロに近いほど、データのクラスター化が進んでいることになります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="5f3f5-228">ただし、クラスター数が増加すると、このメトリックは減少することに注意してください。極端な場合 (個々のデータ ポイントがそれぞれ独自のクラスターである場合)、これはゼロになります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="5f3f5-229">**Davies-Bouldin インデックス**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="5f3f5-230">クラスター内の距離とクラスター間の距離の平均比率です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="5f3f5-231">クラスター自体が密であるほど、またクラスター間が離れるほど、この値は小さくなります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="5f3f5-232">**0** に近い値ほど適当。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-232">Values closer to **0** are better.</span></span> <span data-ttu-id="5f3f5-233">クラスター同士が相互に離れていて、それほど分散していないと、スコアが良くなります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="5f3f5-234">**正規化された相互情報量**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="5f3f5-235">クラスタリング モデルのトレーニングに使用されるトレーニング データに、グラウンド トゥルース ラベル (つまり監視対象クラスタリング) も含まれている場合に使用できます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="5f3f5-236">正規化された相互情報量メトリックは、類似のデータ ポイントが同じクラスターに割り当てられ、異なるデータ ポイントがそれぞれ別のクラスターに割り当てられるかどうかを測定します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="5f3f5-237">正規化された相互情報量の値は 0 から 1 です</span><span class="sxs-lookup"><span data-stu-id="5f3f5-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="5f3f5-238">**1** に近い値ほど適当</span><span class="sxs-lookup"><span data-stu-id="5f3f5-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="5f3f5-239">ランク付けの評価メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="5f3f5-240">メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-240">Metric</span></span>   |      <span data-ttu-id="5f3f5-241">Description</span><span class="sxs-lookup"><span data-stu-id="5f3f5-241">Description</span></span>      |  <span data-ttu-id="5f3f5-242">調査項目</span><span class="sxs-lookup"><span data-stu-id="5f3f5-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="5f3f5-243">**Discounted Cumulative Gain**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="5f3f5-244">Discounted Cumulative Gain (DCG) は、ランク付けの質を表す測定値です。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="5f3f5-245">これは 2 つの前提から派生しています。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-245">It is derived from two assumptions.</span></span> <span data-ttu-id="5f3f5-246">1 つは関連性の高い項目がランキングで高い順位に表示されると、より便利であるということです。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="5f3f5-247">そしてもう 1 つは、有用性は常に関連性と関係している点です。つまり、関連性が高いほど、項目の利便性が高まります。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="5f3f5-248">Discounted Cumulative Gain は、ランキングにおける特定の位置に対して計算され、</span><span class="sxs-lookup"><span data-stu-id="5f3f5-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="5f3f5-249">ランク付けインデックスの対数で割った関連性グレードを、対象となる位置まで合計します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="5f3f5-250">これは $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ を使用して計算されます。関連性グレードは、グラウンド トゥルース ラベルとして、ランク付けトレーニング アルゴリズムに提供されます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="5f3f5-251">ランキング テーブルの位置ごとに 1 つの DCG 値が提供されるため、Discounted Cumulative **Gain (利得)** という名前が付けられています。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="5f3f5-252">**大きい値が適当**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-252">**Higher values are better**</span></span>|
|<span data-ttu-id="5f3f5-253">**Normalized Discounted Cumulative Gains**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="5f3f5-254">DCG を正規化すると、さまざまな長さのランキング リストでメトリックを比較できます</span><span class="sxs-lookup"><span data-stu-id="5f3f5-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="5f3f5-255">**1 に近い値ほど適当**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="5f3f5-256">異常検出の評価メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="5f3f5-257">メトリック</span><span class="sxs-lookup"><span data-stu-id="5f3f5-257">Metric</span></span>   |      <span data-ttu-id="5f3f5-258">Description</span><span class="sxs-lookup"><span data-stu-id="5f3f5-258">Description</span></span>      |  <span data-ttu-id="5f3f5-259">調査項目</span><span class="sxs-lookup"><span data-stu-id="5f3f5-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="5f3f5-260">**Area Under ROC Curve**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="5f3f5-261">受信者動作曲線下面積は、異常なデータ ポイントと通常のデータ ポイントがモデルによってどの程度切り離されているかを測定します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="5f3f5-262">**1 に近い値ほど適当**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="5f3f5-263">0.5 より大きい値のみが、モデルの効果を示します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="5f3f5-264">0.5 以下の値は、モデルが入力を、異常なカテゴリと通常のカテゴリにランダムに割り当てているに過ぎないことを示します</span><span class="sxs-lookup"><span data-stu-id="5f3f5-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="5f3f5-265">**擬陽性数での検出率**</span><span class="sxs-lookup"><span data-stu-id="5f3f5-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="5f3f5-266">擬陽性数での検出率は、テスト セットで正しく特定された異常の数と異常総数の比率で、擬陽性ごとにインデックスが付けられます。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="5f3f5-267">つまり、擬陽性項目ごとに、擬陽性数での検出率の値が存在します。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="5f3f5-268">**1 に近い値ほど適当**。</span><span class="sxs-lookup"><span data-stu-id="5f3f5-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="5f3f5-269">擬陽性がない場合、この値は 1 になります</span><span class="sxs-lookup"><span data-stu-id="5f3f5-269">If there are no false positives, then this value is 1</span></span>|
